{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dd99b1b4",
      "metadata": {
        "id": "dd99b1b4"
      },
      "source": [
        "# Machine Learning Model Comparison & Hyperparameter Tuning\n",
        "\n",
        "This Colab notebook trains multiple classifiers on the UCI Wine dataset, evaluates them with accuracy, precision, recall, and F1-score, and applies GridSearchCV & RandomizedSearchCV to find the best model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc1748d1",
      "metadata": {
        "id": "dc1748d1"
      },
      "source": [
        "## 1. Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ce1d6ea9",
      "metadata": {
        "id": "ce1d6ea9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from scipy.stats import randint, uniform\n",
        "import warnings, json\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df2a3ed6",
      "metadata": {
        "id": "df2a3ed6"
      },
      "source": [
        "## 2. Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6975e3d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6975e3d4",
        "outputId": "763f8bce-d976-4888-e06b-ea7326cc00d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (178, 14), saved as wine.csv\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "wine = load_wine(as_frame=True)\n",
        "df = wine.frame\n",
        "# Save to CSV so the dataset is available as a file (useful when cloning the repo)\n",
        "df.to_csv('wine.csv', index=False)\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(f'Dataset shape: {df.shape}, saved as wine.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a315432",
      "metadata": {
        "id": "1a315432"
      },
      "source": [
        "## 3. Baseline Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "af141cc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af141cc7",
        "outputId": "503cb7e2-a7a6-4f3e-a919-390959e3a4f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline performance:\n",
            "                    accuracy  precision    recall       f1\n",
            "LogisticRegression  0.972222   0.974074  0.972222  0.97197\n",
            "RandomForest        1.000000   1.000000  1.000000  1.00000\n",
            "SVC                 0.972222   0.974074  0.972222  0.97197\n"
          ]
        }
      ],
      "source": [
        "models = {\n",
        "    'LogisticRegression': Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=1000))]),\n",
        "    'RandomForest': RandomForestClassifier(random_state=42),\n",
        "    'SVC': Pipeline([('scaler', StandardScaler()), ('clf', SVC())])\n",
        "}\n",
        "\n",
        "metrics = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    metrics[name] = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision': precision_score(y_test, y_pred, average='weighted'),\n",
        "        'recall': recall_score(y_test, y_pred, average='weighted'),\n",
        "        'f1': f1_score(y_test, y_pred, average='weighted')\n",
        "    }\n",
        "\n",
        "print('Baseline performance:')\n",
        "print(pd.DataFrame(metrics).T)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edec155e",
      "metadata": {
        "id": "edec155e"
      },
      "source": [
        "## 4. Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "035ed63e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "035ed63e",
        "outputId": "c73be789-d318-47c3-867d-f472f0e1f13e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RF params: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n"
          ]
        }
      ],
      "source": [
        "# 4.1 GridSearchCV for RandomForest\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, n_jobs=-1, scoring='f1_weighted')\n",
        "grid_rf.fit(X_train, y_train)\n",
        "print('Best RF params:', grid_rf.best_params_)\n",
        "best_rf = grid_rf.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "117fe67f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "117fe67f",
        "outputId": "edfa2694-9d08-43a9-d625-9ecac77ebcc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVC params: {'clf__C': np.float64(4.419450186421157), 'clf__gamma': np.float64(0.030122914019804194), 'clf__kernel': 'rbf'}\n"
          ]
        }
      ],
      "source": [
        "# 4.2 RandomizedSearchCV for SVC\n",
        "param_dist_svc = {\n",
        "    'clf__C': uniform(0.1, 10),\n",
        "    'clf__gamma': uniform(0.001, 0.1),\n",
        "    'clf__kernel': ['rbf']\n",
        "}\n",
        "\n",
        "rand_svc = RandomizedSearchCV(\n",
        "    Pipeline([('scaler', StandardScaler()), ('clf', SVC())]),\n",
        "    param_distributions=param_dist_svc,\n",
        "    n_iter=20,\n",
        "    cv=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    scoring='f1_weighted'\n",
        ")\n",
        "rand_svc.fit(X_train, y_train)\n",
        "print('Best SVC params:', rand_svc.best_params_)\n",
        "best_svc = rand_svc.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f15f9f1",
      "metadata": {
        "id": "9f15f9f1"
      },
      "source": [
        "## 5. Compare Tuned Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "726a0750",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "726a0750",
        "outputId": "6d0eaeb7-dbef-4442-fb6a-db7969653906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All model performances:\n",
            "                    accuracy  precision    recall       f1\n",
            "RandomForest        1.000000   1.000000  1.000000  1.00000\n",
            "BestRandomForest    1.000000   1.000000  1.000000  1.00000\n",
            "LogisticRegression  0.972222   0.974074  0.972222  0.97197\n",
            "SVC                 0.972222   0.974074  0.972222  0.97197\n",
            "BestSVC             0.944444   0.951389  0.944444  0.94321\n",
            "Selected best model: RandomForest\n"
          ]
        }
      ],
      "source": [
        "tuned_models = {'BestRandomForest': best_rf, 'BestSVC': best_svc}\n",
        "for name, model in tuned_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    metrics[name] = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision': precision_score(y_test, y_pred, average='weighted'),\n",
        "        'recall': recall_score(y_test, y_pred, average='weighted'),\n",
        "        'f1': f1_score(y_test, y_pred, average='weighted')\n",
        "    }\n",
        "\n",
        "results_df = pd.DataFrame(metrics).T.sort_values('f1', ascending=False)\n",
        "print('All model performances:')\n",
        "print(results_df)\n",
        "\n",
        "best_model_name = results_df.index[0]\n",
        "print(f'Selected best model: {best_model_name}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e06c366",
      "metadata": {
        "id": "0e06c366"
      },
      "source": [
        "## 6. Save Best Model (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f0e88a92",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0e88a92",
        "outputId": "da0af9f4-002e-4446-829b-bddecf7b56f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved!\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Check if the best model is in the tuned_models dictionary, otherwise check the original models\n",
        "if best_model_name in tuned_models:\n",
        "    joblib.dump(tuned_models[best_model_name], f'{best_model_name}.joblib')\n",
        "elif best_model_name in models:\n",
        "    joblib.dump(models[best_model_name], f'{best_model_name}.joblib')\n",
        "else:\n",
        "    print(f\"Model '{best_model_name}' not found in tuned_models or models dictionaries.\")\n",
        "\n",
        "print('Model saved!')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}